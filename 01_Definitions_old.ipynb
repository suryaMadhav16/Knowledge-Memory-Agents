{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b360f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Global styles */\n",
       "body {\n",
       "    font-family: 'Crimson Pro', 'Palatino', 'Georgia', serif;\n",
       "    line-height: 1.6;\n",
       "    color: #3c3c3c;\n",
       "    background-color: #fcfbf8;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4 {\n",
       "    font-family: 'Quattrocento Sans', 'Avenir', 'Helvetica Neue', sans-serif;\n",
       "    color: #545454;\n",
       "}\n",
       "\n",
       "/* Custom component styles */\n",
       ".definition-block {\n",
       "    background-color: #e8e2d6;\n",
       "    border-left: 5px solid #ad8e70;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px 20px;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".explanation-block {\n",
       "    background-color: #e5edd0;\n",
       "    border-left: 5px solid #789259;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px 20px;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".resources-block {\n",
       "    background-color: #d6e2e8;\n",
       "    border-left: 5px solid #6a8eaa;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px 20px;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".outcome-block {\n",
       "    background-color: #f0e6d7;\n",
       "    border: 2px solid #c0a080;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px 20px;\n",
       "    margin: 30px 0;\n",
       "    text-align: center;\n",
       "    font-size: 1.1em;\n",
       "}\n",
       "\n",
       ".image-container {\n",
       "    text-align: center;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".grid-container {\n",
       "    display: grid;\n",
       "    grid-template-columns: repeat(2, 1fr);\n",
       "    gap: 20px;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".grid-item {\n",
       "    background-color: #f7f5f0;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px;\n",
       "    box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
       "}\n",
       "\n",
       "code {\n",
       "    background-color: #f0ebe2;\n",
       "    color: #734f3e;\n",
       "    padding: 2px 5px;\n",
       "    border-radius: 4px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Defining custom styling for our notebook components\n",
    "HTML('''\n",
    "<style>\n",
    "/* Global styles */\n",
    "body {\n",
    "    font-family: 'Crimson Pro', 'Palatino', 'Georgia', serif;\n",
    "    line-height: 1.6;\n",
    "    color: #3c3c3c;\n",
    "    background-color: #fcfbf8;\n",
    "}\n",
    "\n",
    "h1, h2, h3, h4 {\n",
    "    font-family: 'Quattrocento Sans', 'Avenir', 'Helvetica Neue', sans-serif;\n",
    "    color: #545454;\n",
    "}\n",
    "\n",
    "/* Custom component styles */\n",
    ".definition-block {\n",
    "    background-color: #e8e2d6;\n",
    "    border-left: 5px solid #ad8e70;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px 20px;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".explanation-block {\n",
    "    background-color: #e5edd0;\n",
    "    border-left: 5px solid #789259;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px 20px;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".resources-block {\n",
    "    background-color: #d6e2e8;\n",
    "    border-left: 5px solid #6a8eaa;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px 20px;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".outcome-block {\n",
    "    background-color: #f0e6d7;\n",
    "    border: 2px solid #c0a080;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px 20px;\n",
    "    margin: 30px 0;\n",
    "    text-align: center;\n",
    "    font-size: 1.1em;\n",
    "}\n",
    "\n",
    ".image-container {\n",
    "    text-align: center;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".grid-container {\n",
    "    display: grid;\n",
    "    grid-template-columns: repeat(2, 1fr);\n",
    "    gap: 20px;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".grid-item {\n",
    "    background-color: #f7f5f0;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
    "}\n",
    "\n",
    "code {\n",
    "    background-color: #f0ebe2;\n",
    "    color: #734f3e;\n",
    "    padding: 2px 5px;\n",
    "    border-radius: 4px;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae434bf",
   "metadata": {},
   "source": [
    "# Building Intelligent Agents with Memory & Knowledge\n",
    "\n",
    "Welcome to the first section of our crash course on developing intelligent agent systems. This notebook is your guide to understanding and implementing the fundamental building blocks of modern AI agents.\n",
    "\n",
    "## What You'll Learn in This Crash Course\n",
    "\n",
    "This crash course will take you on a journey from understanding the core concepts of knowledge, memory, and agency in AI systems to implementing sophisticated agentic architectures using LangGraph. We'll explore how these components interact to create systems that can reason, remember, and act autonomously to achieve complex goals.\n",
    "\n",
    "<div class=\"outcome-block\">\n",
    "By the end of this course, you'll be able to design, implement, and evaluate advanced AI agent systems that effectively utilize knowledge retrieval and memory to solve real-world problems.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475f9a0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Quick setup to ensure our custom blocks display correctly in the notebook\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_definition(text):\n",
    "    display(Markdown(f'<div class=\"definition-block\">{text}</div>'))\n",
    "    \n",
    "def show_explanation(text):\n",
    "    display(Markdown(f'<div class=\"explanation-block\">{text}</div>'))\n",
    "    \n",
    "def show_resources(text):\n",
    "    display(Markdown(f'<div class=\"resources-block\">{text}</div>'))\n",
    "\n",
    "def show_grid(items, columns=2):\n",
    "    html = '<div class=\"grid-container\" style=\"grid-template-columns: repeat(' + str(columns) + ', 1fr);\">'\n",
    "    for item in items:\n",
    "        html += f'<div class=\"grid-item\">{item}</div>'\n",
    "    html += '</div>'\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336a591",
   "metadata": {},
   "source": [
    "## 1. Definitions: Knowledge, Memory, and Agents\n",
    "\n",
    "Before diving into implementation details, we need to establish a clear understanding of the fundamental concepts that form the foundation of our course.\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The field of generative AI has evolved rapidly from simple language models to sophisticated agentic systems. This evolution has been marked by increasing capabilities in knowledge retrieval, memory utilization, and autonomous decision-making. Understanding these core concepts is essential for building effective AI systems that can assist with complex tasks.\n",
    "\n",
    "Let's begin by exploring the fundamental definitions and relationships between knowledge, memory, and agents in AI systems.\n",
    "\n",
    "### Knowledge in AI Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea34ffa1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"definition-block\"><strong>Knowledge</strong>: Information that AI systems can access and utilize to perform tasks, answer questions, and make decisions. It represents the \"what\" of AI understanding - facts, concepts, and relationships that the system knows about the world.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_definition(\"<strong>Knowledge</strong>: Information that AI systems can access and utilize to perform tasks, answer questions, and make decisions. It represents the \\\"what\\\" of AI understanding - facts, concepts, and relationships that the system knows about the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71aa2e8",
   "metadata": {},
   "source": [
    "#### Types of Knowledge in AI\n",
    "\n",
    "AI systems access knowledge through two primary mechanisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4477dcff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h4>Parametric Knowledge</h4>\n",
       "    Information encoded directly within the model's weights during training. This knowledge is \"baked into\" the model itself.</div><div class=\"grid-item\"><h4>Non-Parametric Knowledge</h4>\n",
       "    Information stored outside the model's parameters, typically in external databases or knowledge bases that can be queried at runtime.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h4>Parametric Knowledge</h4>\n",
    "    Information encoded directly within the model's weights during training. This knowledge is \"baked into\" the model itself.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Non-Parametric Knowledge</h4>\n",
    "    Information stored outside the model's parameters, typically in external databases or knowledge bases that can be queried at runtime.\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85e5c5",
   "metadata": {},
   "source": [
    "##### Parametric Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c7a3ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"explanation-block\"><strong>Characteristics of Parametric Knowledge:</strong>\n",
       "<ul>\n",
       "<li>Stored within the model's parameters (weights and biases)</li>\n",
       "<li>Fixed after training (without fine-tuning or retraining)</li>\n",
       "<li>Fast to access, as it requires no external lookup</li>\n",
       "<li>May become outdated as the world changes</li>\n",
       "<li>Limited by model size and training data</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_explanation(\"\"\"<strong>Characteristics of Parametric Knowledge:</strong>\n",
    "<ul>\n",
    "<li>Stored within the model's parameters (weights and biases)</li>\n",
    "<li>Fixed after training (without fine-tuning or retraining)</li>\n",
    "<li>Fast to access, as it requires no external lookup</li>\n",
    "<li>May become outdated as the world changes</li>\n",
    "<li>Limited by model size and training data</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8691e",
   "metadata": {},
   "source": [
    "For example, when a large language model (LLM) knows that \"Paris is the capital of France\" without looking it up externally, it's using parametric knowledge stored in its weights.\n",
    "\n",
    "##### Non-Parametric Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77c57b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"explanation-block\"><strong>Characteristics of Non-Parametric Knowledge:</strong>\n",
       "<ul>\n",
       "<li>Stored in external systems (databases, knowledge graphs, documents)</li>\n",
       "<li>Can be updated without retraining the model</li>\n",
       "<li>Requires retrieval mechanisms (search, lookup)</li>\n",
       "<li>Easily expandable without changing the model itself</li>\n",
       "<li>May increase latency due to retrieval time</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_explanation(\"\"\"<strong>Characteristics of Non-Parametric Knowledge:</strong>\n",
    "<ul>\n",
    "<li>Stored in external systems (databases, knowledge graphs, documents)</li>\n",
    "<li>Can be updated without retraining the model</li>\n",
    "<li>Requires retrieval mechanisms (search, lookup)</li>\n",
    "<li>Easily expandable without changing the model itself</li>\n",
    "<li>May increase latency due to retrieval time</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341cec4c",
   "metadata": {},
   "source": [
    "When an AI system looks up current weather data or retrieves information from a company's database, it's utilizing non-parametric knowledge.\n",
    "\n",
    "#### Knowledge Representation Methods\n",
    "\n",
    "How knowledge is represented significantly impacts how AI systems can use it. Common knowledge representation methods include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1f71d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h4>Vector Embeddings</h4>\n",
       "    Represent concepts, words, or documents as numerical vectors in a high-dimensional space, where semantic similarity is captured by vector proximity.</div><div class=\"grid-item\"><h4>Knowledge Graphs</h4>\n",
       "    Structured representations of knowledge as a network of entities (nodes) and relationships (edges) between them.</div><div class=\"grid-item\"><h4>Symbolic Representations</h4>\n",
       "    Formal logical structures that enable reasoning through rules and relationships, often using predicate logic.</div><div class=\"grid-item\"><h4>Distributed Representations</h4>\n",
       "    Information distributed across many parameters, as in neural networks, where knowledge is represented implicitly across connections.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h4>Vector Embeddings</h4>\n",
    "    Represent concepts, words, or documents as numerical vectors in a high-dimensional space, where semantic similarity is captured by vector proximity.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Knowledge Graphs</h4>\n",
    "    Structured representations of knowledge as a network of entities (nodes) and relationships (edges) between them.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Symbolic Representations</h4>\n",
    "    Formal logical structures that enable reasoning through rules and relationships, often using predicate logic.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Distributed Representations</h4>\n",
    "    Information distributed across many parameters, as in neural networks, where knowledge is represented implicitly across connections.\"\"\"\n",
    "], columns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcddca2",
   "metadata": {},
   "source": [
    "##### Vector Embeddings Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640d9b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_utils because of the following error (look up to see its traceback):\ncannot import name 'DiagnosticOptions' from 'torch.onnx._internal.exporter' (/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/onnx/_internal/exporter/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1968\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/modeling_utils.py:55\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/integrations/flex_attention.py:46\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     42\u001b[0m         create_block_mask \u001b[38;5;28;01mas\u001b[39;00m create_block_causal_mask_flex,\n\u001b[1;32m     43\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWrappedFlexAttention\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    We are doing a singleton class so that flex attention is compiled once when it's first called.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/integrations/flex_attention.py:61\u001b[0m, in \u001b[0;36mWrappedFlexAttention\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mdisable(recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Initialize or update the singleton instance.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/compiler/__init__.py:96\u001b[0m, in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mThis function provides both a decorator and a context manager to disable compilation on a function\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03mIt also provides the option of recursively disabling called functions\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    recursive (optional): A boolean value indicating whether the disabling should be recursive.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_traceback_short\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompilerFn\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     BuiltinVariable,\n\u001b[1;32m     52\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     53\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     54\u001b[0m     SkipFunctionVariable,\n\u001b[1;32m     55\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[1;32m     56\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     57\u001b[0m     UserMethodVariable,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py:34\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     FunctoolsPartialVariable,\n\u001b[1;32m     29\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     UserMethodVariable,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     36\u001b[0m     TorchHigherOrderOperatorVariable,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     CountIteratorVariable,\n\u001b[1;32m     40\u001b[0m     CycleIteratorVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     RepeatIteratorVariable,\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy_to_fake_tensor, get_fake_value, get_real_value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/onnx/__init__.py:46\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     _optimize_graph,\n\u001b[1;32m     36\u001b[0m     _run_symbolic_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     unregister_custom_op_symbolic,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. needs to be last to avoid circular import\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     DiagnosticOptions,\n\u001b[1;32m     48\u001b[0m     ExportOptions,\n\u001b[1;32m     49\u001b[0m     ONNXProgram,\n\u001b[1;32m     50\u001b[0m     ONNXProgramSerializer,\n\u001b[1;32m     51\u001b[0m     ONNXRuntimeOptions,\n\u001b[1;32m     52\u001b[0m     InvalidExportOptionsError,\n\u001b[1;32m     53\u001b[0m     OnnxExporterError,\n\u001b[1;32m     54\u001b[0m     OnnxRegistry,\n\u001b[1;32m     55\u001b[0m     dynamo_export,\n\u001b[1;32m     56\u001b[0m     enable_fake_mode,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     is_onnxrt_backend_supported,\n\u001b[1;32m     61\u001b[0m     OrtBackend \u001b[38;5;28;01mas\u001b[39;00m _OrtBackend,\n\u001b[1;32m     62\u001b[0m     OrtBackendOptions \u001b[38;5;28;01mas\u001b[39;00m _OrtBackendOptions,\n\u001b[1;32m     63\u001b[0m     OrtExecutionProvider \u001b[38;5;28;01mas\u001b[39;00m _OrtExecutionProvider,\n\u001b[1;32m     64\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DiagnosticOptions' from 'torch.onnx._internal.exporter' (/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/onnx/_internal/exporter/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1968\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1956\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1956\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1957\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1970\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1973\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\ncannot import name 'DiagnosticOptions' from 'torch.onnx._internal.exporter' (/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/onnx/_internal/exporter/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Creating word embeddings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis is the capital of France\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBerlin is the capital of Germany\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/__init__.py:14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[1;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[1;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/evaluation/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMSEEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSEEvaluator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMSEEvaluatorFromDataFrame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSEEvaluatorFromDataFrame\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNanoBEIREvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NanoBEIREvaluator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParaphraseMiningEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParaphraseMiningEvaluator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRerankingEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RerankingEvaluator\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mInformationRetrievalEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InformationRetrievalEvaluator\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/sentence_transformers/model_card.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1956\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1956\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1957\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/transformers/utils/import_utils.py:1970\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1973\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_utils because of the following error (look up to see its traceback):\ncannot import name 'DiagnosticOptions' from 'torch.onnx._internal.exporter' (/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/torch/onnx/_internal/exporter/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Example: Creating word embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = [\"Paris is the capital of France\", \"Berlin is the capital of Germany\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be1568",
   "metadata": {},
   "source": [
    "##### Knowledge Graph Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b026d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample knowledge graph:\n",
      "{\n",
      "  \"Paris\": {\n",
      "    \"is_capital_of\": \"France\",\n",
      "    \"population\": \"2.2 million\"\n",
      "  },\n",
      "  \"France\": {\n",
      "    \"has_capital\": \"Paris\",\n",
      "    \"continent\": \"Europe\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example: Simple knowledge graph representation\n",
    "graph = {\n",
    "    \"Paris\": {\"is_capital_of\": \"France\", \"population\": \"2.2 million\"},\n",
    "    \"France\": {\"has_capital\": \"Paris\", \"continent\": \"Europe\"}\n",
    "}\n",
    "print(\"Sample knowledge graph:\")\n",
    "import json\n",
    "print(json.dumps(graph, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef86a3be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"resources-block\"><strong>Key Resources on Knowledge in AI:</strong>\n",
       "<ul>\n",
       "<li><a href=\"https://medium.com/towards-data-science/knowledge-retrieval-takes-center-stage-183be733c6e8\" target=\"_blank\">Gadi Singer's \"Knowledge Retrieval Takes Center Stage\"</a> explores the shift from parametric to retrieval-centric models</li>\n",
       "<li><a href=\"https://medium.com/towards-data-science/seat-of-knowledge-ai-systems-with-deeply-structure-knowledge-37f1a5ab4bc5\" target=\"_blank\">\"Seat of Knowledge: AI Systems with Deeply Structured Knowledge\"</a> provides a classification of AI systems based on knowledge representation</li>\n",
       "<li><a href=\"https://www.ibm.com/think/topics/agentic-rag\" target=\"_blank\">IBM's research on knowledge integration in AI systems</a> offers practical approaches to combining parametric and non-parametric knowledge</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_resources(\"\"\"<strong>Key Resources on Knowledge in AI:</strong>\n",
    "<ul>\n",
    "<li><a href=\"https://medium.com/towards-data-science/knowledge-retrieval-takes-center-stage-183be733c6e8\" target=\"_blank\">Gadi Singer's \"Knowledge Retrieval Takes Center Stage\"</a> explores the shift from parametric to retrieval-centric models</li>\n",
    "<li><a href=\"https://medium.com/towards-data-science/seat-of-knowledge-ai-systems-with-deeply-structure-knowledge-37f1a5ab4bc5\" target=\"_blank\">\"Seat of Knowledge: AI Systems with Deeply Structured Knowledge\"</a> provides a classification of AI systems based on knowledge representation</li>\n",
    "<li><a href=\"https://www.ibm.com/think/topics/agentic-rag\" target=\"_blank\">IBM's research on knowledge integration in AI systems</a> offers practical approaches to combining parametric and non-parametric knowledge</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbfbf0",
   "metadata": {},
   "source": [
    "### Memory in AI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bd6672",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"definition-block\"><strong>Memory</strong>: An AI system's ability to store and recall past experiences, interactions, or computational states to maintain context and influence future behavior. Memory enables persistence and continuity in AI systems.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_definition(\"<strong>Memory</strong>: An AI system's ability to store and recall past experiences, interactions, or computational states to maintain context and influence future behavior. Memory enables persistence and continuity in AI systems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84cbe5",
   "metadata": {},
   "source": [
    "#### Differentiating Memory from Knowledge\n",
    "\n",
    "While knowledge and memory are related concepts, they serve different functions in AI systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ee845aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"explanation-block\"><strong>Knowledge vs. Memory:</strong>\n",
       "<ul>\n",
       "<li><strong>Knowledge</strong> is about factual information and understanding of concepts (the \"what\")</li>\n",
       "<li><strong>Memory</strong> is about recording experiences and context over time (the \"when\" and \"how\")</li>\n",
       "<li><strong>Knowledge</strong> might tell an AI about calendar systems and how dates work</li>\n",
       "<li><strong>Memory</strong> helps an AI remember that the user scheduled a meeting last Tuesday</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_explanation(\"\"\"<strong>Knowledge vs. Memory:</strong>\n",
    "<ul>\n",
    "<li><strong>Knowledge</strong> is about factual information and understanding of concepts (the \"what\")</li>\n",
    "<li><strong>Memory</strong> is about recording experiences and context over time (the \"when\" and \"how\")</li>\n",
    "<li><strong>Knowledge</strong> might tell an AI about calendar systems and how dates work</li>\n",
    "<li><strong>Memory</strong> helps an AI remember that the user scheduled a meeting last Tuesday</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538bc6d",
   "metadata": {},
   "source": [
    "This distinction becomes particularly important when designing AI systems that need to maintain context across multiple interactions with users.\n",
    "\n",
    "#### Types of Memory in AI Systems\n",
    "\n",
    "AI systems implement several forms of memory, inspired by human cognitive systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286683f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h4>Short-term Memory (Working Memory)</h4>\n",
       "    Temporary storage for ongoing conversations or tasks, typically limited in scope and duration.</div><div class=\"grid-item\"><h4>Episodic Memory</h4>\n",
       "    Records specific past experiences and interactions, similar to how humans remember events.</div><div class=\"grid-item\"><h4>Semantic Memory</h4>\n",
       "    Stores structured factual knowledge, definitions, and rules about specific domains.</div><div class=\"grid-item\"><h4>Procedural Memory</h4>\n",
       "    Contains information about how to perform tasks or follow processes.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h4>Short-term Memory (Working Memory)</h4>\n",
    "    Temporary storage for ongoing conversations or tasks, typically limited in scope and duration.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Episodic Memory</h4>\n",
    "    Records specific past experiences and interactions, similar to how humans remember events.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Semantic Memory</h4>\n",
    "    Stores structured factual knowledge, definitions, and rules about specific domains.\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Procedural Memory</h4>\n",
    "    Contains information about how to perform tasks or follow processes.\"\"\"\n",
    "], columns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb961b71",
   "metadata": {},
   "source": [
    "##### Implementation Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae0eabf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h5>Short-term Memory</h5>\n",
       "    <ul>\n",
       "    <li>Storing recent conversation turns in context window</li>\n",
       "    <li>Maintaining state within a session</li>\n",
       "    <li>Tracking active goals and subtasks</li>\n",
       "    </ul></div><div class=\"grid-item\"><h5>Episodic Memory</h5>\n",
       "    <ul>\n",
       "    <li>Conversation logs with timestamps</li>\n",
       "    <li>Interaction history databases</li>\n",
       "    <li>Vector databases of past exchanges</li>\n",
       "    </ul></div><div class=\"grid-item\"><h5>Semantic Memory</h5>\n",
       "    <ul>\n",
       "    <li>Knowledge graphs of user preferences</li>\n",
       "    <li>Structured databases of learned facts</li>\n",
       "    <li>Vector stores of semantic information</li>\n",
       "    </ul></div><div class=\"grid-item\"><h5>Procedural Memory</h5>\n",
       "    <ul>\n",
       "    <li>Stored procedures or functions</li>\n",
       "    <li>Task templates and workflows</li>\n",
       "    <li>Learned patterns for multi-step processes</li>\n",
       "    </ul></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h5>Short-term Memory</h5>\n",
    "    <ul>\n",
    "    <li>Storing recent conversation turns in context window</li>\n",
    "    <li>Maintaining state within a session</li>\n",
    "    <li>Tracking active goals and subtasks</li>\n",
    "    </ul>\"\"\",\n",
    "    \n",
    "    \"\"\"<h5>Episodic Memory</h5>\n",
    "    <ul>\n",
    "    <li>Conversation logs with timestamps</li>\n",
    "    <li>Interaction history databases</li>\n",
    "    <li>Vector databases of past exchanges</li>\n",
    "    </ul>\"\"\",\n",
    "    \n",
    "    \"\"\"<h5>Semantic Memory</h5>\n",
    "    <ul>\n",
    "    <li>Knowledge graphs of user preferences</li>\n",
    "    <li>Structured databases of learned facts</li>\n",
    "    <li>Vector stores of semantic information</li>\n",
    "    </ul>\"\"\",\n",
    "    \n",
    "    \"\"\"<h5>Procedural Memory</h5>\n",
    "    <ul>\n",
    "    <li>Stored procedures or functions</li>\n",
    "    <li>Task templates and workflows</li>\n",
    "    <li>Learned patterns for multi-step processes</li>\n",
    "    </ul>\"\"\"\n",
    "], columns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccd5f2",
   "metadata": {},
   "source": [
    "#### Importance of Memory for AI Agents\n",
    "\n",
    "Memory capabilities are essential for creating persistent, context-aware AI agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dec97ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(3, 1fr);\"><div class=\"grid-item\"><strong>Continuity</strong><br>Enables coherent multi-turn interactions</div><div class=\"grid-item\"><strong>Personalization</strong><br>Allows agents to adapt to individual users over time</div><div class=\"grid-item\"><strong>Learning</strong><br>Provides experiences from which to improve performance</div><div class=\"grid-item\"><strong>Relationship Building</strong><br>Creates a sense of persistence and familiarity</div><div class=\"grid-item\"><strong>Complex Task Management</strong><br>Supports handling of multi-stage processes</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<strong>Continuity</strong><br>Enables coherent multi-turn interactions\"\"\",\n",
    "    \"\"\"<strong>Personalization</strong><br>Allows agents to adapt to individual users over time\"\"\",\n",
    "    \"\"\"<strong>Learning</strong><br>Provides experiences from which to improve performance\"\"\",\n",
    "    \"\"\"<strong>Relationship Building</strong><br>Creates a sense of persistence and familiarity\"\"\",\n",
    "    \"\"\"<strong>Complex Task Management</strong><br>Supports handling of multi-stage processes\"\"\"\n",
    "], columns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf6ea10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"resources-block\"><strong>Key Resources on Memory in AI:</strong>\n",
       "<ul>\n",
       "<li><a href=\"https://www.ibm.com/think/topics/ai-agent-memory\" target=\"_blank\">IBM's comprehensive guide on \"What Is AI Agent Memory?\"</a> explores different memory types and implementations</li>\n",
       "<li><a href=\"https://blog.langchain.dev/memory-for-agents/\" target=\"_blank\">\"Memory for agents\" from the LangChain Blog</a> discusses practical memory implementations for agent systems</li>\n",
       "<li><a href=\"https://decodingml.substack.com/p/memory-the-secret-sauce-of-ai-agents\" target=\"_blank\">\"Memory: The secret sauce of AI agents\" from Decoding ML</a> details how different memory types enhance agent capabilities</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_resources(\"\"\"<strong>Key Resources on Memory in AI:</strong>\n",
    "<ul>\n",
    "<li><a href=\"https://www.ibm.com/think/topics/ai-agent-memory\" target=\"_blank\">IBM's comprehensive guide on \"What Is AI Agent Memory?\"</a> explores different memory types and implementations</li>\n",
    "<li><a href=\"https://blog.langchain.dev/memory-for-agents/\" target=\"_blank\">\"Memory for agents\" from the LangChain Blog</a> discusses practical memory implementations for agent systems</li>\n",
    "<li><a href=\"https://decodingml.substack.com/p/memory-the-secret-sauce-of-ai-agents\" target=\"_blank\">\"Memory: The secret sauce of AI agents\" from Decoding ML</a> details how different memory types enhance agent capabilities</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25aaf5",
   "metadata": {},
   "source": [
    "### Agents in Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d89df10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"definition-block\"><strong>Agents</strong>: Autonomous systems that perceive their environment, make decisions, and take actions to achieve specific goals. AI agents use generative models as their reasoning engine while incorporating additional capabilities for interaction and task completion.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_definition(\"<strong>Agents</strong>: Autonomous systems that perceive their environment, make decisions, and take actions to achieve specific goals. AI agents use generative models as their reasoning engine while incorporating additional capabilities for interaction and task completion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c677b7",
   "metadata": {},
   "source": [
    "#### Components of AI Agents\n",
    "\n",
    "Modern AI agents typically consist of several interdependent components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15117b32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h4>1. Perception</h4>\n",
       "    Mechanisms for receiving and processing input from the environment or users.<br><br>\n",
       "    <strong>Examples:</strong> Natural language understanding, vision systems, data connectors</div><div class=\"grid-item\"><h4>2. Reasoning</h4>\n",
       "    Cognitive capabilities for understanding, planning, and decision-making.<br><br>\n",
       "    <strong>Examples:</strong> LLMs for reasoning, planning systems, domain-specific models</div><div class=\"grid-item\"><h4>3. Memory</h4>\n",
       "    Systems for storing and retrieving past experiences and knowledge.<br><br>\n",
       "    <strong>Examples:</strong> Short-term context, long-term storage, episodic records</div><div class=\"grid-item\"><h4>4. Action</h4>\n",
       "    Capabilities for executing decisions and interacting with the environment.<br><br>\n",
       "    <strong>Examples:</strong> Tool usage (APIs), text generation, database operations</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h4>1. Perception</h4>\n",
    "    Mechanisms for receiving and processing input from the environment or users.<br><br>\n",
    "    <strong>Examples:</strong> Natural language understanding, vision systems, data connectors\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>2. Reasoning</h4>\n",
    "    Cognitive capabilities for understanding, planning, and decision-making.<br><br>\n",
    "    <strong>Examples:</strong> LLMs for reasoning, planning systems, domain-specific models\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>3. Memory</h4>\n",
    "    Systems for storing and retrieving past experiences and knowledge.<br><br>\n",
    "    <strong>Examples:</strong> Short-term context, long-term storage, episodic records\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>4. Action</h4>\n",
    "    Capabilities for executing decisions and interacting with the environment.<br><br>\n",
    "    <strong>Examples:</strong> Tool usage (APIs), text generation, database operations\"\"\"\n",
    "], columns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016a4be",
   "metadata": {},
   "source": [
    "#### Evolution from Basic LLMs to Agentic Systems\n",
    "\n",
    "The progression from simple language models to agentic systems represents a significant evolution in AI capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "029e9f5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(2, 1fr);\"><div class=\"grid-item\"><h4>Stage 1: Basic Language Models</h4>\n",
       "    Generate text based on prompts without agency or persistence.\n",
       "    <pre>\n",
       "    User: \"What is the capital of France?\"\n",
       "    LLM: \"The capital of France is Paris.\"\n",
       "    </pre></div><div class=\"grid-item\"><h4>Stage 2: Conversational AI</h4>\n",
       "    Maintain context within a conversation but limited to textual interaction.\n",
       "    <pre>\n",
       "    User: \"What is the capital of France?\"\n",
       "    AI: \"The capital of France is Paris.\"\n",
       "    User: \"What is its population?\"\n",
       "    AI: \"Paris has a population of approximately 2.2 million people.\"\n",
       "    </pre></div><div class=\"grid-item\"><h4>Stage 3: Tool-Using AI</h4>\n",
       "    Capable of using external tools and APIs to accomplish tasks beyond text generation.\n",
       "    <pre>\n",
       "    User: \"What's the weather in Tokyo right now?\"\n",
       "    AI: [Calls weather API] \"Currently in Tokyo, it's 22C (72F) and partly cloudy.\"\n",
       "    </pre></div><div class=\"grid-item\"><h4>Stage 4: Agentic Systems</h4>\n",
       "    Autonomous systems that can plan, reason, and execute complex multi-step tasks with minimal supervision.\n",
       "    <pre>\n",
       "    User: \"Plan my trip to Paris next month.\"\n",
       "    Agent: [Plans itinerary, checks flights, books accommodations, creates cohesive plan across multiple tools and data sources]\n",
       "    </pre></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<h4>Stage 1: Basic Language Models</h4>\n",
    "    Generate text based on prompts without agency or persistence.\n",
    "    <pre>\n",
    "    User: \"What is the capital of France?\"\n",
    "    LLM: \"The capital of France is Paris.\"\n",
    "    </pre>\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Stage 2: Conversational AI</h4>\n",
    "    Maintain context within a conversation but limited to textual interaction.\n",
    "    <pre>\n",
    "    User: \"What is the capital of France?\"\n",
    "    AI: \"The capital of France is Paris.\"\n",
    "    User: \"What is its population?\"\n",
    "    AI: \"Paris has a population of approximately 2.2 million people.\"\n",
    "    </pre>\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Stage 3: Tool-Using AI</h4>\n",
    "    Capable of using external tools and APIs to accomplish tasks beyond text generation.\n",
    "    <pre>\n",
    "    User: \"What's the weather in Tokyo right now?\"\n",
    "    AI: [Calls weather API] \"Currently in Tokyo, it's 22C (72F) and partly cloudy.\"\n",
    "    </pre>\"\"\",\n",
    "    \n",
    "    \"\"\"<h4>Stage 4: Agentic Systems</h4>\n",
    "    Autonomous systems that can plan, reason, and execute complex multi-step tasks with minimal supervision.\n",
    "    <pre>\n",
    "    User: \"Plan my trip to Paris next month.\"\n",
    "    Agent: [Plans itinerary, checks flights, books accommodations, creates cohesive plan across multiple tools and data sources]\n",
    "    </pre>\"\"\"\n",
    "], columns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4c3b34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"resources-block\"><strong>Key Resources on AI Agents:</strong>\n",
       "<ul>\n",
       "<li><a href=\"https://www.ibm.com/think/topics/agentic-reasoning\" target=\"_blank\">IBM's \"What Is Agentic Reasoning?\"</a> provides insights into the decision-making capabilities of agents</li>\n",
       "<li><a href=\"https://ajithp.com/2025/04/05/llm-based-intelligent-agents/\" target=\"_blank\">\"LLM-Based Intelligent Agents: Architecture and Evolution\"</a> offers a comprehensive look at agent architecture</li>\n",
       "<li><a href=\"https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\" target=\"_blank\">\"Agentic AI 101\" from Pryon</a> explores the components and capabilities of agentic systems</li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_resources(\"\"\"<strong>Key Resources on AI Agents:</strong>\n",
    "<ul>\n",
    "<li><a href=\"https://www.ibm.com/think/topics/agentic-reasoning\" target=\"_blank\">IBM's \"What Is Agentic Reasoning?\"</a> provides insights into the decision-making capabilities of agents</li>\n",
    "<li><a href=\"https://ajithp.com/2025/04/05/llm-based-intelligent-agents/\" target=\"_blank\">\"LLM-Based Intelligent Agents: Architecture and Evolution\"</a> offers a comprehensive look at agent architecture</li>\n",
    "<li><a href=\"https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\" target=\"_blank\">\"Agentic AI 101\" from Pryon</a> explores the components and capabilities of agentic systems</li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2afad8",
   "metadata": {},
   "source": [
    "### Relationships Between Knowledge, Memory, and Agency\n",
    "\n",
    "These three concepts are deeply interconnected in advanced AI systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59da7241",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"grid-container\" style=\"grid-template-columns: repeat(3, 1fr);\"><div class=\"grid-item\"><strong>Knowledge</strong> provides the information foundation upon which agents operate</div><div class=\"grid-item\"><strong>Memory</strong> creates persistence and learning capabilities across interactions</div><div class=\"grid-item\"><strong>Agency</strong> enables autonomous goal-directed behavior using knowledge and memory</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid([\n",
    "    \"\"\"<strong>Knowledge</strong> provides the information foundation upon which agents operate\"\"\",\n",
    "    \"\"\"<strong>Memory</strong> creates persistence and learning capabilities across interactions\"\"\",\n",
    "    \"\"\"<strong>Agency</strong> enables autonomous goal-directed behavior using knowledge and memory\"\"\"\n",
    "], columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fbb47",
   "metadata": {},
   "source": [
    "Together, they form the foundation for building sophisticated AI systems that can assist with complex tasks, adapt to user needs, and operate with increasing levels of autonomy.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Knowledge** encompasses the information AI systems can access and utilize, whether stored in model parameters or external sources\n",
    "- **Memory** enables AI systems to maintain context and learn from experiences over time through various storage mechanisms\n",
    "- **Agents** are autonomous systems that combine perception, reasoning, memory, and action capabilities to accomplish goals\n",
    "- These three components form the foundation of advanced AI systems, with each playing a critical role in overall system capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4ed960",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"resources-block\"><strong>Further Reading:</strong>\n",
       "<ul>\n",
       "<li><a href=\"https://diamantai.substack.com/p/building-an-ai-agent-with-memory\" target=\"_blank\">\"Building an AI Agent with Memory and Adaptability\" - DiamantAI</a></li>\n",
       "<li><a href=\"https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\" target=\"_blank\">\"Agentic AI 101: How to Unlock the Power of AI Agents\" - Pryon</a></li>\n",
       "<li><a href=\"https://odsc.medium.com/rag-in-2024-the-evolution-of-ai-powered-knowledge-retrieval-6d273b822c14\" target=\"_blank\">\"RAG in 2024: The Evolution of AI-Powered Knowledge Retrieval\"</a></li>\n",
       "<li><a href=\"https://python.langchain.com/docs/versions/migrating_memory/long_term_memory_agent/\" target=\"_blank\">\"A Long-Term Memory Agent\" - LangChain Documentation</a></li>\n",
       "</ul></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_resources(\"\"\"<strong>Further Reading:</strong>\n",
    "<ul>\n",
    "<li><a href=\"https://diamantai.substack.com/p/building-an-ai-agent-with-memory\" target=\"_blank\">\"Building an AI Agent with Memory and Adaptability\" - DiamantAI</a></li>\n",
    "<li><a href=\"https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\" target=\"_blank\">\"Agentic AI 101: How to Unlock the Power of AI Agents\" - Pryon</a></li>\n",
    "<li><a href=\"https://odsc.medium.com/rag-in-2024-the-evolution-of-ai-powered-knowledge-retrieval-6d273b822c14\" target=\"_blank\">\"RAG in 2024: The Evolution of AI-Powered Knowledge Retrieval\"</a></li>\n",
    "<li><a href=\"https://python.langchain.com/docs/versions/migrating_memory/long_term_memory_agent/\" target=\"_blank\">\"A Long-Term Memory Agent\" - LangChain Documentation</a></li>\n",
    "</ul>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac431e42",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the following sections, we'll explore these concepts in greater depth, focusing on implementation approaches for knowledge retrieval systems, memory architectures, and agentic frameworks using LangGraph and related technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7975e1f-7154-429b-b3fd-f677919ac0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a76eb-dcdc-4cec-96fe-3b3a2773feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
