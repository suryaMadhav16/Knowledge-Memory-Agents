{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdaa1b0",
   "metadata": {},
   "source": [
    "# Building Intelligent Agents: Knowledge, Memory, and Agency with LangGraph\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "By the end of this course, you'll be able to design, implement, and evaluate advanced AI agent systems that effectively utilize knowledge retrieval and memory to solve real-world problems.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the first section of our crash course on developing intelligent agent systems with LangGraph. Before diving into implementation details, we need to establish a clear understanding of the fundamental concepts that form the foundation of our course.\n",
    "\n",
    "The field of generative AI has evolved rapidly from simple language models to sophisticated agentic systems. This evolution has been marked by increasing capabilities in knowledge retrieval, memory utilization, and autonomous decision-making. Understanding these core concepts is essential for building effective AI systems that can assist with complex tasks.\n",
    "\n",
    "Let's begin by exploring the fundamental definitions and relationships between knowledge, memory, and agents in AI systems.\n",
    "\n",
    "## 1. Knowledge in AI Systems\n",
    "\n",
    "**Knowledge**: Information that AI systems can access and utilize to perform tasks, answer questions, and make decisions. It represents the \"what\" of AI understanding - facts, concepts, and relationships that the system knows about the world.\n",
    "\n",
    "### Types of Knowledge in AI\n",
    "\n",
    "AI systems access knowledge through two primary mechanisms:\n",
    "\n",
    "#### 1.1 Parametric Knowledge\n",
    "\n",
    "Parametric knowledge refers to information encoded directly within the model's weights during training. This knowledge is \"baked into\" the model itself.\n",
    "\n",
    "**Characteristics of Parametric Knowledge:**\n",
    "- Stored within the model's parameters (weights and biases)\n",
    "- Fixed after training (without fine-tuning or retraining)\n",
    "- Fast to access, as it requires no external lookup\n",
    "- May become outdated as the world changes\n",
    "- Limited by model size and training data\n",
    "\n",
    "For example, when a large language model (LLM) knows that \"Paris is the capital of France\" without looking it up externally, it's using parametric knowledge stored in its weights.\n",
    "\n",
    "#### 1.2 Non-Parametric Knowledge\n",
    "\n",
    "Non-parametric knowledge is information stored outside the model's parameters, typically in external databases or knowledge bases that can be queried at runtime.\n",
    "\n",
    "**Characteristics of Non-Parametric Knowledge:**\n",
    "- Stored in external systems (databases, knowledge graphs, documents)\n",
    "- Can be updated without retraining the model\n",
    "- Requires retrieval mechanisms (search, lookup)\n",
    "- Easily expandable without changing the model itself\n",
    "- May increase latency due to retrieval time\n",
    "\n",
    "When an AI system looks up current weather data or retrieves information from a company's database, it's utilizing non-parametric knowledge.\n",
    "\n",
    "### Knowledge Representation Methods\n",
    "\n",
    "How knowledge is represented significantly impacts how AI systems can use it. Common knowledge representation methods include:\n",
    "\n",
    "#### Vector Embeddings\n",
    "\n",
    "Represent concepts, words, or documents as numerical vectors in a high-dimensional space, where semantic similarity is captured by vector proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c455651d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcheck_call([sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Importing the necessary library  \u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis is the capital of France\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBerlin is the capital of Germany\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(sentences)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# Add a check to ensure a package is installed\n",
    "import importlib.util\n",
    "def is_package_installed(package_name):\n",
    "    return importlib.util.find_spec(package_name) is not None\n",
    "# If not installed, install the package\n",
    "if not is_package_installed('sentence_transformers'):\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sentence-transformers'])\n",
    "# Importing the necessary library  \n",
    "from sentence_transformers import SentenceTransformer   \n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = [\"Paris is the capital of France\", \"Berlin is the capital of Germany\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77c745",
   "metadata": {},
   "source": [
    "#### Knowledge Graphs\n",
    "\n",
    "Structured representations of knowledge as a network of entities (nodes) and relationships (edges) between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple knowledge graph representation\n",
    "graph = {\n",
    "    \"Paris\": {\"is_capital_of\": \"France\", \"population\": \"2.2 million\"},\n",
    "    \"France\": {\"has_capital\": \"Paris\", \"continent\": \"Europe\"}\n",
    "}\n",
    "import json\n",
    "print(json.dumps(graph, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032cce6c",
   "metadata": {},
   "source": [
    "#### Symbolic Representations\n",
    "\n",
    "Formal logical structures that enable reasoning through rules and relationships, often using predicate logic.\n",
    "\n",
    "```\n",
    "# Example (conceptual): Symbolic representation using predicate logic\n",
    "# is_capital_of(Paris, France)\n",
    "# ∀x,y: is_capital_of(x, y) → has_capital(y, x)\n",
    "```\n",
    "\n",
    "#### Distributed Representations\n",
    "\n",
    "Information distributed across many parameters, as in neural networks, where knowledge is represented implicitly across connections.\n",
    "\n",
    "**Key Resources on Knowledge in AI:**\n",
    "- Gadi Singer's \"Knowledge Retrieval Takes Center Stage\" explores the shift from parametric to retrieval-centric models: https://medium.com/towards-data-science/knowledge-retrieval-takes-center-stage-183be733c6e8\n",
    "- \"Seat of Knowledge: AI Systems with Deeply Structured Knowledge\" provides a classification of AI systems based on knowledge representation: https://medium.com/towards-data-science/seat-of-knowledge-ai-systems-with-deeply-structure-knowledge-37f1a5ab4bc5\n",
    "- IBM's research on knowledge integration in AI systems offers practical approaches to combining parametric and non-parametric knowledge: https://www.ibm.com/think/topics/agentic-rag\n",
    "\n",
    "## 2. Memory in AI Agents\n",
    "\n",
    "**Memory**: An AI system's ability to store and recall past experiences, interactions, or computational states to maintain context and influence future behavior. Memory enables persistence and continuity in AI systems.\n",
    "\n",
    "### Differentiating Memory from Knowledge\n",
    "\n",
    "While knowledge and memory are related concepts, they serve different functions in AI systems:\n",
    "\n",
    "**Knowledge vs. Memory:**\n",
    "- **Knowledge** is about factual information and understanding of concepts (the \"what\")\n",
    "- **Memory** is about recording experiences and context over time (the \"when\" and \"how\")\n",
    "- **Knowledge** might tell an AI about calendar systems and how dates work\n",
    "- **Memory** helps an AI remember that the user scheduled a meeting last Tuesday\n",
    "\n",
    "This distinction becomes particularly important when designing AI systems that need to maintain context across multiple interactions with users.\n",
    "\n",
    "### Types of Memory in AI Systems\n",
    "\n",
    "AI systems implement several forms of memory, inspired by human cognitive systems:\n",
    "\n",
    "#### 2.1 Short-term Memory (Working Memory)\n",
    "\n",
    "Temporary storage for ongoing conversations or tasks, typically limited in scope and duration.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Storing recent conversation turns in context window\n",
    "- Maintaining state within a session\n",
    "- Tracking active goals and subtasks\n",
    "\n",
    "#### 2.2 Long-term Memory\n",
    "\n",
    "Persistent storage that maintains information across multiple sessions or extended periods. Long-term memory in AI systems typically takes several forms:\n",
    "\n",
    "##### Episodic Memory\n",
    "\n",
    "Records specific past experiences and interactions.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Conversation logs with timestamps\n",
    "- Interaction history databases\n",
    "- Vector databases of past exchanges\n",
    "\n",
    "##### Semantic Memory\n",
    "\n",
    "Stores structured factual knowledge, definitions, and rules.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Knowledge graphs of user preferences\n",
    "- Structured databases of learned facts\n",
    "- Vector stores of semantic information\n",
    "\n",
    "##### Procedural Memory\n",
    "\n",
    "Contains information about how to perform tasks or follow processes.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Stored procedures or functions\n",
    "- Task templates and workflows\n",
    "- Learned patterns for multi-step processes\n",
    "\n",
    "### Importance of Memory for AI Agents\n",
    "\n",
    "Memory capabilities are essential for creating persistent, context-aware AI agents:\n",
    "\n",
    "- **Continuity**: Enables coherent multi-turn interactions\n",
    "- **Personalization**: Allows agents to adapt to individual users over time\n",
    "- **Learning**: Provides experiences from which to improve performance\n",
    "- **Relationship Building**: Creates a sense of persistence and familiarity\n",
    "- **Complex Task Management**: Supports handling of multi-stage processes\n",
    "\n",
    "**Key Resources on Memory in AI:**\n",
    "- IBM's comprehensive guide on \"What Is AI Agent Memory?\" explores different memory types and implementations: https://www.ibm.com/think/topics/ai-agent-memory\n",
    "- \"Memory for agents\" from the LangChain Blog discusses practical memory implementations for agent systems: https://blog.langchain.dev/memory-for-agents/\n",
    "- \"Memory: The secret sauce of AI agents\" from Decoding ML details how different memory types enhance agent capabilities: https://decodingml.substack.com/p/memory-the-secret-sauce-of-ai-agents\n",
    "\n",
    "## 3. Agents in Generative AI\n",
    "\n",
    "**Agents**: Autonomous systems that perceive their environment, make decisions, and take actions to achieve specific goals. AI agents use generative models as their reasoning engine while incorporating additional capabilities for interaction and task completion.\n",
    "\n",
    "### Components of AI Agents\n",
    "\n",
    "Modern AI agents typically consist of several interdependent components:\n",
    "\n",
    "#### 3.1 Perception\n",
    "\n",
    "Mechanisms for receiving and processing input from the environment or users.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Natural language understanding for text inputs\n",
    "- Vision systems for image/video processing\n",
    "- Sensors for physical environments (in embodied AI)\n",
    "- Data connectors for digital environments\n",
    "\n",
    "#### 3.2 Reasoning\n",
    "\n",
    "Cognitive capabilities for understanding, planning, and decision-making.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Large language models for general reasoning\n",
    "- Planning systems for multi-step tasks\n",
    "- Specialized domain models for specific areas\n",
    "- Agentic reasoning patterns (e.g., ReAct, Reflection)\n",
    "\n",
    "#### 3.3 Memory\n",
    "\n",
    "Systems for storing and retrieving past experiences and knowledge, as discussed above.\n",
    "\n",
    "#### 3.4 Action\n",
    "\n",
    "Capabilities for executing decisions and interacting with the environment.\n",
    "\n",
    "**Implementation Approaches:**\n",
    "- Tool usage (APIs, functions, services)\n",
    "- Text generation for communication\n",
    "- Database operations for data management\n",
    "- Actuators for physical environments (robotics)\n",
    "\n",
    "### Evolution from Basic LLMs to Agentic Systems\n",
    "\n",
    "The progression from simple language models to agentic systems represents a significant evolution in AI capabilities:\n",
    "\n",
    "#### Stage 1: Basic Language Models\n",
    "\n",
    "Generate text based on prompts without agency or persistence.\n",
    "\n",
    "```\n",
    "User: \"What is the capital of France?\"\n",
    "LLM: \"The capital of France is Paris.\"\n",
    "```\n",
    "\n",
    "#### Stage 2: Conversational AI\n",
    "\n",
    "Maintain context within a conversation but limited to textual interaction.\n",
    "\n",
    "```\n",
    "User: \"What is the capital of France?\"\n",
    "AI: \"The capital of France is Paris.\"\n",
    "User: \"What is its population?\"\n",
    "AI: \"Paris has a population of approximately 2.2 million people in the city proper.\"\n",
    "```\n",
    "\n",
    "#### Stage 3: Tool-Using AI\n",
    "\n",
    "Capable of using external tools and APIs to accomplish tasks beyond text generation.\n",
    "\n",
    "```\n",
    "User: \"What's the weather in Tokyo right now?\"\n",
    "AI: [Calls weather API] \"Currently in Tokyo, it's 22°C (72°F) and partly cloudy.\"\n",
    "```\n",
    "\n",
    "#### Stage 4: Agentic Systems\n",
    "\n",
    "Autonomous systems that can plan, reason, and execute complex multi-step tasks with minimal supervision.\n",
    "\n",
    "```\n",
    "User: \"Plan my trip to Paris next month.\"\n",
    "Agent: [Plans itinerary, checks flights, suggests accommodations, identifies attractions based on user preferences, and creates a cohesive plan across multiple tools and data sources]\n",
    "```\n",
    "\n",
    "**Key Resources on AI Agents:**\n",
    "- IBM's \"What Is Agentic Reasoning?\" provides insights into the decision-making capabilities of agents: https://www.ibm.com/think/topics/agentic-reasoning\n",
    "- \"LLM-Based Intelligent Agents: Architecture and Evolution\" offers a comprehensive look at agent architecture: https://ajithp.com/2025/04/05/llm-based-intelligent-agents/\n",
    "- \"Agentic AI 101\" from Pryon explores the components and capabilities of agentic systems: https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\n",
    "\n",
    "## 4. Relationships Between Knowledge, Memory, and Agency\n",
    "\n",
    "These three concepts are deeply interconnected in advanced AI systems:\n",
    "\n",
    "- **Knowledge** provides the information foundation upon which agents operate\n",
    "- **Memory** creates persistence and learning capabilities across interactions\n",
    "- **Agency** enables autonomous goal-directed behavior using knowledge and memory\n",
    "\n",
    "Together, they form the foundation for building sophisticated AI systems that can assist with complex tasks, adapt to user needs, and operate with increasing levels of autonomy.\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Knowledge** encompasses the information AI systems can access and utilize, whether stored in model parameters or external sources\n",
    "- **Memory** enables AI systems to maintain context and learn from experiences over time through various storage mechanisms\n",
    "- **Agents** are autonomous systems that combine perception, reasoning, memory, and action capabilities to accomplish goals\n",
    "- These three components form the foundation of advanced AI systems, with each playing a critical role in overall system capabilities\n",
    "\n",
    "**Further Reading:**\n",
    "- \"Building an AI Agent with Memory and Adaptability\" - DiamantAI: https://diamantai.substack.com/p/building-an-ai-agent-with-memory\n",
    "- \"Agentic AI 101: How to Unlock the Power of AI Agents\" - Pryon: https://www.pryon.com/landing/agentic-ai-101-how-to-unlock-the-power-of-ai-agents\n",
    "- \"RAG in 2024: The Evolution of AI-Powered Knowledge Retrieval\": https://odsc.medium.com/rag-in-2024-the-evolution-of-ai-powered-knowledge-retrieval-6d273b822c14\n",
    "- \"A Long-Term Memory Agent\" - LangChain Documentation: https://python.langchain.com/docs/versions/migrating_memory/long_term_memory_agent/\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the following sections, we'll explore these concepts in greater depth, focusing on implementation approaches for knowledge retrieval systems, memory architectures, and agentic frameworks using LangGraph and related technologies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getting-started-llmops",
   "language": "python",
   "name": "getting-started-llmops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
